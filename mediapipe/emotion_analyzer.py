#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# ê°ì • ë¶„ì„ê¸° - ì–¼êµ´ í‘œì •ê³¼ ì œìŠ¤ì²˜ë¥¼ ì¡°í•©í•œ ê°ì • ì¸ì‹
import cv2 # OpenCV ë¼ì´ë¸ŒëŸ¬ë¦¬, ë¹„ë””ì˜¤ ë° ì´ë¯¸ì§€ ì²˜ë¦¬ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
import mediapipe as mp # MediaPipe ë¼ì´ë¸ŒëŸ¬ë¦¬, ì–¼êµ´ ë©”ì‹œ ë° ì† ì¶”ì ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
import numpy as np # NumPy ë¼ì´ë¸ŒëŸ¬ë¦¬, ìˆ˜ì¹˜ ê³„ì‚°ì— ì‚¬ìš©ë©ë‹ˆë‹¤.

# MediaPipe ì´ˆê¸°í™”
mp_face_mesh = mp.solutions.face_mesh # MediaPipeì˜ ì–¼êµ´ ë©”ì‹œ ì†”ë£¨ì…˜ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
mp_hands = mp.solutions.hands # MediaPipeì˜ ì† ì¶”ì  ì†”ë£¨ì…˜ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
mp_drawing = mp.solutions.drawing_utils # MediaPipeì˜ ê·¸ë¦¬ê¸° ê´€ë ¨ ìœ í‹¸ë¦¬í‹°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

def analyze_face_emotion(landmarks):
    """ì–¼êµ´ ëœë“œë§ˆí¬ë¡œ ê°ì • ë¶„ì„"""
    # ì…ê¼¬ë¦¬ ìœ„ì¹˜ë¡œ ë¯¸ì†Œ ê°ì§€
    mouth_left = landmarks[61]  # ì… ì™¼ìª½ ë ëœë“œë§ˆí¬
    mouth_right = landmarks[291] # ì… ì˜¤ë¥¸ìª½ ë ëœë“œë§ˆí¬
    mouth_center = landmarks[13] # ì… ì¤‘ì•™ ì•„ë˜ ëœë“œë§ˆí¬
    
    # ì…ê¼¬ë¦¬ê°€ ì… ì¤‘ì•™ë³´ë‹¤ ì–¼ë§ˆë‚˜ ìœ„/ì•„ë˜ì— ìˆëŠ”ì§€ ê³„ì‚°í•˜ì—¬ ë¯¸ì†Œ ì •ë„ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.
    mouth_curve = (mouth_left.y + mouth_right.y) / 2 - mouth_center.y
    
    # ëˆˆì¹ ìœ„ì¹˜ë¡œ ë†€ëŒ/í™”ë‚¨ ê°ì§€
    left_eyebrow = landmarks[70]  # ì™¼ìª½ ëˆˆì¹ ëœë“œë§ˆí¬
    right_eyebrow = landmarks[300] # ì˜¤ë¥¸ìª½ ëˆˆì¹ ëœë“œë§ˆí¬
    nose_tip = landmarks[1]      # ì½”ë ëœë“œë§ˆí¬
    
    # ëˆˆì¹ì´ ì½”ëë³´ë‹¤ ì–¼ë§ˆë‚˜ ìœ„ì— ìˆëŠ”ì§€ ê³„ì‚°í•˜ì—¬ ëˆˆì¹ì˜ ì›€ì§ì„ì„ íŒŒì•…í•©ë‹ˆë‹¤.
    eyebrow_height = (left_eyebrow.y + right_eyebrow.y) / 2 - nose_tip.y
    
    # ê°ì • íŒë³„
    if mouth_curve < -0.01:  # ì…ê¼¬ë¦¬ê°€ ê¸°ì¤€ë³´ë‹¤ ë§ì´ ì˜¬ë¼ê°€ ìˆìœ¼ë©´ (yì¢Œí‘œëŠ” ìœ„ë¡œ ê°ˆìˆ˜ë¡ ì‘ì•„ì§)
        return "í–‰ë³µ ğŸ˜Š"
    elif mouth_curve > 0.01: # ì…ê¼¬ë¦¬ê°€ ê¸°ì¤€ë³´ë‹¤ ë§ì´ ë‚´ë ¤ê°€ ìˆìœ¼ë©´
        return "ìŠ¬í”” ğŸ˜¢"
    elif eyebrow_height < -0.05: # ëˆˆì¹ì´ ê¸°ì¤€ë³´ë‹¤ ë§ì´ ì˜¬ë¼ê°€ ìˆìœ¼ë©´
        return "ë†€ëŒ ğŸ˜®"
    else: # ê·¸ ì™¸ì˜ ê²½ìš°
        return "í‰ì˜¨ ğŸ˜"

def analyze_hand_gesture(hand_landmarks):
    """ì† ì œìŠ¤ì²˜ë¡œ ê°ì •/ì˜ë„ ë¶„ì„"""
    # ê° ì†ê°€ë½ ëì ì˜ ëœë“œë§ˆí¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    thumb_tip = hand_landmarks.landmark[4]
    index_tip = hand_landmarks.landmark[8]
    middle_tip = hand_landmarks.landmark[12]
    ring_tip = hand_landmarks.landmark[16]
    pinky_tip = hand_landmarks.landmark[20]
    
    # ì†ëª©ì„ ê¸°ì¤€ì ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    wrist = hand_landmarks.landmark[0]
    
    # ê° ì†ê°€ë½ì´ í´ì ¸ìˆëŠ”ì§€ í™•ì¸í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥í•©ë‹ˆë‹¤. (1: í´ì§, 0: ì ‘í˜)
    fingers_up = []
    
    # ì—„ì§€ëŠ” x ì¢Œí‘œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í´ì§/ì ‘í˜ì„ íŒë‹¨í•©ë‹ˆë‹¤. (ì†ì˜ ë°©í–¥ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ)
    if thumb_tip.x > hand_landmarks.landmark[3].x:
        fingers_up.append(1)
    else:
        fingers_up.append(0)
    
    # ë‚˜ë¨¸ì§€ 4ê°œ ì†ê°€ë½ì€ y ì¢Œí‘œë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤. (ì†ê°€ë½ ëì´ ì¤‘ê°„ ê´€ì ˆë³´ë‹¤ ìœ„ì— ìˆìœ¼ë©´ í´ì§„ ê²ƒ)
    finger_tips = [8, 12, 16, 20]  # ê²€ì§€, ì¤‘ì§€, ì•½ì§€, ì†Œì§€ ëì  ì¸ë±ìŠ¤
    finger_pips = [6, 10, 14, 18]  # ê° ì†ê°€ë½ì˜ ì¤‘ê°„ ê´€ì ˆ(PIP) ì¸ë±ìŠ¤
    
    for tip, pip in zip(finger_tips, finger_pips):
        if hand_landmarks.landmark[tip].y < hand_landmarks.landmark[pip].y:
            fingers_up.append(1)
        else:
            fingers_up.append(0)
    
    # ì œìŠ¤ì²˜ íŒë³„
    total_fingers = sum(fingers_up) # í´ì§„ ì†ê°€ë½ì˜ ì´ ê°œìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    if total_fingers == 0:
        return "ì£¼ë¨¹ âœŠ"
    elif total_fingers == 5:
        return "ì•ˆë…• ğŸ‘‹"
    elif fingers_up == [0, 1, 1, 0, 0]: # ê²€ì§€ì™€ ì¤‘ì§€ë§Œ í´ì§„ ê²½ìš°
        return "í‰í™” âœŒï¸"
    elif fingers_up == [1, 0, 0, 0, 0]: # ì—„ì§€ë§Œ í´ì§„ ê²½ìš°
        return "ì¢‹ì•„ìš” ğŸ‘"
    elif total_fingers == 1 and fingers_up[1] == 1: # ê²€ì§€ë§Œ í´ì§„ ê²½ìš°
        return "ê°€ë¦¬í‚¤ê¸° ğŸ‘†"
    else:
        return f"ì†ê°€ë½ {total_fingers}ê°œ"

# ì›¹ìº  ì‹œì‘
cap = cv2.VideoCapture(0) # 0ë²ˆ ì¹´ë©”ë¼(ê¸°ë³¸ ì›¹ìº )ë¥¼ ì—½ë‹ˆë‹¤.

# MediaPipe ì–¼êµ´ ë©”ì‹œì™€ ì† ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
with mp_face_mesh.FaceMesh(
    max_num_faces=1,          # ìµœëŒ€ 1ê°œì˜ ì–¼êµ´ë§Œ ê°ì§€
    refine_landmarks=True,    # ëˆˆ, ì…ìˆ  ì£¼ë³€ ëœë“œë§ˆí¬ ì •êµí™”
    min_detection_confidence=0.5, # ìµœì†Œ ê°ì§€ ì‹ ë¢°ë„
    min_tracking_confidence=0.5) as face_mesh, \
     mp_hands.Hands(
        min_detection_confidence=0.5, # ìµœì†Œ ê°ì§€ ì‹ ë¢°ë„
        min_tracking_confidence=0.5) as hands:

    while cap.isOpened(): # ì›¹ìº ì´ ì—´ë ¤ ìˆëŠ” ë™ì•ˆ ê³„ì† ë°˜ë³µí•©ë‹ˆë‹¤.
        ret, frame = cap.read() # ì›¹ìº ì—ì„œ í•œ í”„ë ˆì„ì„ ì½ì–´ì˜µë‹ˆë‹¤.
        if not ret: # í”„ë ˆì„ì„ ì œëŒ€ë¡œ ì½ì–´ì˜¤ì§€ ëª»í–ˆë‹¤ë©´ ë£¨í”„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.
            break

        # ì´ë¯¸ì§€ ì²˜ë¦¬
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # ì´ë¯¸ì§€ë¥¼ BGRì—ì„œ RGBë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        image.flags.writeable = False # ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ ì´ë¯¸ì§€ì— ì“°ê¸° ì‘ì—…ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.
        
        # ì–¼êµ´ê³¼ ì† ê°ì§€
        face_results = face_mesh.process(image) # ì–¼êµ´ ë©”ì‹œ ëª¨ë¸ë¡œ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        hand_results = hands.process(image) # ì† ëª¨ë¸ë¡œ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        # ì´ë¯¸ì§€ ë‹¤ì‹œ ë³€í™˜
        image.flags.writeable = True # í™”ë©´ì— ê·¸ë¦¬ê¸° ìœ„í•´ ì“°ê¸° ì‘ì—…ì„ ë‹¤ì‹œ í™œì„±í™”í•©ë‹ˆë‹¤.
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ RGBì—ì„œ BGRë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        # ì–¼êµ´ ê°ì • ë¶„ì„
        face_emotion = "ì–¼êµ´ ì¸ì‹ ì•ˆë¨" # ê¸°ë³¸ ê°ì • ìƒíƒœ
        if face_results.multi_face_landmarks: # ê°ì§€ëœ ì–¼êµ´ì´ ìˆìœ¼ë©´
            for face_landmarks in face_results.multi_face_landmarks: # ê° ì–¼êµ´ì— ëŒ€í•´ ë°˜ë³µ
                face_emotion = analyze_face_emotion(face_landmarks.landmark) # ê°ì • ë¶„ì„ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
                
                # ì£¼ìš” ì–¼êµ´ í¬ì¸íŠ¸ë§Œ ê·¸ë¦¬ê¸° (ì‹œê°í™”ë¥¼ ìœ„í•´)
                for i in [1, 61, 291, 13, 70, 300]:  # ì½”ë, ì…ê¼¬ë¦¬, ì… ì¤‘ì•™, ëˆˆì¹ í¬ì¸íŠ¸
                    # ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
                    x = int(face_landmarks.landmark[i].x * frame.shape[1])
                    y = int(face_landmarks.landmark[i].y * frame.shape[0])
                    cv2.circle(image, (x, y), 3, (0, 255, 0), -1) # í•´ë‹¹ ìœ„ì¹˜ì— ì›ì„ ê·¸ë¦½ë‹ˆë‹¤.
        
        # ì† ì œìŠ¤ì²˜ ë¶„ì„
        hand_gesture = "ì† ì¸ì‹ ì•ˆë¨" # ê¸°ë³¸ ì œìŠ¤ì²˜ ìƒíƒœ
        if hand_results.multi_hand_landmarks: # ê°ì§€ëœ ì†ì´ ìˆìœ¼ë©´
            for hand_landmarks in hand_results.multi_hand_landmarks: # ê° ì†ì— ëŒ€í•´ ë°˜ë³µ
                hand_gesture = analyze_hand_gesture(hand_landmarks) # ì œìŠ¤ì²˜ ë¶„ì„ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
                mp_drawing.draw_landmarks( # ì† ëœë“œë§ˆí¬ì™€ ì—°ê²°ì„ ì„ ê·¸ë¦½ë‹ˆë‹¤.
                    image, hand_landmarks, mp_hands.HAND_CONNECTIONS)
        
        # ê²°ê³¼ í‘œì‹œ
        cv2.putText(image, f'Face: {face_emotion}', 
                   (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2, cv2.LINE_AA) # ì–¼êµ´ ê°ì • ê²°ê³¼ë¥¼ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.
        
        cv2.putText(image, f'Hand: {hand_gesture}', 
                   (10, 70), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2, cv2.LINE_AA) # ì† ì œìŠ¤ì²˜ ê²°ê³¼ë¥¼ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.
        
        # ì¢…í•© ìƒíƒœ
        if "í–‰ë³µ" in face_emotion and "ì¢‹ì•„ìš”" in hand_gesture:
            overall_mood = "ë§¤ìš° ê¸ì •ì ! ğŸŒŸ"
            color = (0, 255, 0) # ì´ˆë¡ìƒ‰
        elif "ìŠ¬í””" in face_emotion:
            overall_mood = "ìœ„ë¡œê°€ í•„ìš”í•´ìš” ğŸ’™"
            color = (255, 0, 0) # íŒŒë€ìƒ‰
        elif "í‰í™”" in hand_gesture:
            overall_mood = "í‰í™”ë¡œìš´ ìƒíƒœ â˜®ï¸"
            color = (0, 255, 255) # ë…¸ë€ìƒ‰
        else:
            overall_mood = "ì¼ë°˜ì ì¸ ìƒíƒœ"
            color = (255, 255, 255) # í°ìƒ‰
        
        cv2.putText(image, overall_mood, 
                   (10, 110), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2, cv2.LINE_AA) # ì¢…í•©ì ì¸ ìƒíƒœë¥¼ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.
        
        cv2.imshow('Emotion Analyzer', image) # ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ì°½ì— ë³´ì—¬ì¤ë‹ˆë‹¤.
        
        if cv2.waitKey(10) & 0xFF == ord('q'): # 'q' í‚¤ê°€ ëˆŒë¦¬ë©´ ë£¨í”„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.
            break

cap.release() # ì‚¬ìš©ì´ ëë‚œ ì›¹ìº  ë¦¬ì†ŒìŠ¤ë¥¼ í•´ì œí•©ë‹ˆë‹¤.
cv2.destroyAllWindows() # ëª¨ë“  OpenCV ì°½ì„ ë‹«ìŠµë‹ˆë‹¤.